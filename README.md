# Adjustable_musicLDM 

本プロジェクトは、拡散モデル（Diffusion Models）を活用し、作成済みの音楽をプロンプトで再度調整できる作曲支援AIを提案・実装したものである。従来のText-to-Musicモデルでは不可能だった「音楽の再度調整」を可能にし、作曲者の意図により近づけた音楽生成体験を提供。

## 📌 概要

- **目的**: 生成済み音楽に対してプロンプトを通じて再調整（微修正）を行えるAIの提案。
- **背景**: 一般的なText-to-Musicモデルでは、音楽は一度きりのランダム生成で、生成後の修正ができなかった。
- **提案手法**: 音楽に再びノイズを加えてから新たなプロンプトを条件として与え、元音源の要素を残しつつも意図的な変化を加える仕組みを実現。


## 🔧 使用技術・モデル構成

- **CLAP (Contrastive Language-Audio Pretraining)**  
  テキストと音声を共通の潜在空間にマッピングし、対応関係を学習。

- **Latent Diffusion Models (LDM)**  
  潜在変数空間に対してノイズ付加と除去を行うことで、生成効率を高めた拡散モデル。

- **MusicLDM**  
  CLAPとLDMを組み合わせた音楽生成モデル。プロンプトに応じた音楽を任意秒数で生成可能。

- **モデル構成図**
<img width="444" alt="image" src="https://github.com/user-attachments/assets/df04f3f7-41be-4fdf-bb4d-51885181a629" />


## 🔁 音楽の再調整手法

1. 生成済み音楽ファイルをモデルに再入力。
2. ノイズを任意の割合（例: 元音源:ノイズ = 6:4）で付加。
3. 新しいプロンプトを与えてノイズ除去（デノイジング）。
4. 元音源を保持しつつプロンプト内容を反映させた音楽を生成。

## 🎵 元音源と調整後音楽

[元音源と調整後音楽の例](https://www.notion.so/hhhslab/6-1b5afc8cdfc380f58ae0dbe85d047a96?source=copy_link)


## 🧪 評価

### ✅ 定性的評価

- 再調整された音楽は、元のメロディなどを保持しつつ、新プロンプトの特徴が明確に反映。
- メルスペクトログラムにより視覚的にも変化が確認できる。

### 📊 定量的評価

- CLAPで音源とプロンプトをベクトル化し、以下を比較：
  - 元音源 vs プロンプト
  - 調整後音源 vs プロンプト
- 結果として、調整後の方がユークリッド距離が短く、コサイン類似度が高い → ベクトル的に「プロンプトに近づいた」ことを確認。


### ✏️ プロンプト形式の比較

- 短文プロンプト vs 長文プロンプトの比較を実施。
- 長文プロンプトの方がより音楽的要素を含み、バランス良く調整される傾向が確認された。
- ただし、ユークリッド距離・コサイン類似度の標準偏差には大きな差は見られず、定性的な違いの定量化には限界があると示唆される

## 💻 実行環境

| パーツ | スペック |
|--------|----------|
| OS     | Windows 10 Pro Education |
| CPU    | Intel Core i9-14900KF 3.20GHz |
| GPU    | NVIDIA GeForce RTX 3090 |

## 🔮 今後の課題・展望

- プロンプトのさらなる工夫（プロンプトエンジニアリング）
- 音楽の部分的な調整や、転調・拍子の変化の導入
- 調整結果の評価手法・精度向上

---
